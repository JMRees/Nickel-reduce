{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photometry in Python - Photutils, DAOFIND, and Aperture Photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on a series created by Stuart Littlefair at the University of Sheffield. \n",
    "It also makes use of 'phot_helpers.py', a set of useful scripts created by Stuart Littlefair for photometry.\n",
    "\n",
    "\n",
    "## Steps\n",
    "\n",
    "At the end of this notebook you should be able to measure magnitudes for stars in your calibrated Nickel images. \n",
    "\n",
    "The steps are:\n",
    "1. Finding the stars in our image;\n",
    "2. Measuring instrumental magnitudes (photometry);\n",
    "3. Determining an astrometric solution using astrometry.net;\n",
    "4. Matching stars to an all-sky survey to determine photometric zeropoints;\n",
    "5. Applying the calculated zeropoints to transform between instrumental and calibrated magnitudes;\n",
    "6. Plotting the results in a colour-magnitude diagram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setting up Astrometry.net\n",
    "\n",
    "We will use astrometry.net to determine an astrometric solution for our images. \n",
    "\n",
    "An astrometric solution will allow us to transform pixel (X-Y) co-ordinates to RA-Dec co-ordinates for all of the stars in our image. \n",
    "\n",
    "Astrometry.net provide the source code, so we could build the application oursevles, and use their index images to determine our astrometric solution. But in practice, it's much easier to use their web service for our purposes.\n",
    "\n",
    "To use astrometry.net's web-based servives we need an API key. The API key is a unique identifier telling astrometry.net who you are. \n",
    "\n",
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<font color='green'>\n",
    "<h2><span class=\"fa fa-pencil\"></span> Set up astrometry.net API </h2>\n",
    "</font>\n",
    "**Create an account with astrometry.net:**\n",
    "https://nova.astrometry.net/\n",
    "\n",
    "**Then navigate to the 'API' tab. \n",
    "Copy your API key and add it below. Or you can add it to the 'astroquery.cfg' file, then move this file to ~/.astropy/config/**\n",
    "    \n",
    "</div>\n",
    "</section>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.astrometry_net import AstrometryNet\n",
    "ast = AstrometryNet()\n",
    "#ast.api_key = '##########'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photometry with Photutils\n",
    "\n",
    "Many tools exist to perform photometry (IRAF, GAIA, AstroImageJ etc.)\n",
    "We are going to be using the Python package [photutils](http://photutils.readthedocs.org/en/latest/) to do most of the heavy lifting for us.\n",
    "\n",
    "If you do not have photutils already installed, the code cell below will install it. Run this cell, and if there are any **errors**, ask for help (warnings are ok/expected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install photutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if this code cell runs without error, you have successfully installed photutils!\n",
    "import photutils as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Aperture Photometry\n",
    "\n",
    "Now we'll make a couple of functions to make life easier later. \n",
    "\n",
    "The first will perform aperture photometry. The second will plot the full-width at half-maximum for a star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to perform aperture photometry\n",
    "from photutils.utils import calc_total_error\n",
    "from photutils.aperture import CircularAperture\n",
    "from photutils.aperture import CircularAnnulus\n",
    "import astropy.stats as st\n",
    "import warnings\n",
    "from astropy.wcs import WCS\n",
    "def aperture_photometry(data, header, sources, aperture_radius, sky_inner_radius, sky_outer_radius):\n",
    "    \"\"\"\n",
    "    Calculate Aperture Photometry on a list of sources\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data:  `np.ndarray`\n",
    "        A 2D array of pixel values of your data. From a FITS file, you can create this array with\n",
    "        `fits.getdata`.\n",
    "\n",
    "    header: `~astropy.fits.Header`\n",
    "        A FITS Header object. From a FITS file, you can create this object with\n",
    "        `fits.getheader`.\n",
    "\n",
    "    sources: `~astropy.table.Table`\n",
    "        A table of detected sources for the image. Usually, `photutils.DAOStarFinder` would be\n",
    "        used to create this list.\n",
    "\n",
    "    aperture_radius: float\n",
    "        Radius of the target aperture, in pixels\n",
    "\n",
    "    sky_inner_radius: float\n",
    "        Radius of the inner aperture that makes up the sky annulus\n",
    "\n",
    "    sky_outer_radius: float\n",
    "        Radius of the outer aperture that makes up the sky annulus\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    phot_table: `~astropy.table.Table`\n",
    "        A table of measurements for each source, including instrumental magnitude and error.\n",
    "    \"\"\"\n",
    "    # make apertures around sources, and annuli for sky estimation\n",
    "    positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "    apertures = CircularAperture(positions, r=aperture_radius)\n",
    "    sky_annulus = CircularAnnulus(positions,\n",
    "                                    r_in=sky_inner_radius, r_out=sky_outer_radius)\n",
    "    annulus_masks = sky_annulus.to_mask(method='center')\n",
    "\n",
    "    # aperture photometry - calculates total counts in apertures, with errors\n",
    "    # calc_total_error uses CCD SNR equation \n",
    "    error_arr = calc_total_error(data, 12.0, egain)\n",
    "    phot_table = p.aperture.aperture_photometry(data, apertures, error=error_arr)\n",
    "\n",
    "    # calculate the Sky background. Because the sky annulus might have other\n",
    "    # stars inside it, we will take a CLIPPED MEAN of the counts in the annulus\n",
    "    # to try and reject the contribution from stars.\n",
    "    bkg_mean = []\n",
    "    for mask in annulus_masks:\n",
    "        annulus_data = mask.multiply(data)\n",
    "        annulus_data_1d = annulus_data[mask.data > 0]\n",
    "        mean_sigclip, _, _ = st.sigma_clipped_stats(annulus_data_1d)\n",
    "        bkg_mean.append(mean_sigclip)\n",
    "\n",
    "    # now we know the mean sky counts. We multiply by ratio of annulus area to\n",
    "    # target aperture area. This gives expected number of sky counts in target\n",
    "    # aperture.\n",
    "    bkg_mean = np.array(bkg_mean)\n",
    "    phot_table['sky_mean'] = bkg_mean\n",
    "    phot_table['aper_bkg'] = bkg_mean * apertures.area\n",
    "    phot_table['aper_sum_bksub'] = phot_table['aperture_sum'] - phot_table['aper_bkg']\n",
    "\n",
    "    # Tricky bit now! We want to know what Right Ascension and Declination\n",
    "    # each pixel corresponds to. We will use the information in the FITS header\n",
    "    # (the so-called \"World Coordinate System\") to work this out. \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        wcs = WCS(header)\n",
    "    ra, dec = wcs.all_pix2world(phot_table['xcenter'], phot_table['ycenter'], 0)\n",
    "    phot_table['RA'] = ra\n",
    "    phot_table['DEC'] = dec\n",
    "\n",
    "    # Calculate Instrumental Magnitude and Error\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        phot_table['instrumental_mag'] = -2.5*np.log10(phot_table['aper_sum_bksub'] / header['EXPTIME'])\n",
    "    phot_table['e_instrumental_mag'] = phot_table['aperture_sum_err'] / phot_table['aper_sum_bksub']\n",
    "\n",
    "    return phot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this function later to measure FWHM in our images\n",
    "def measure_FWHM(data, sources):\n",
    "    # averagely bright stars\n",
    "    lims = np.percentile(sources['flux'], (60, 70))\n",
    "    mask = reduce(\n",
    "        np.logical_and,\n",
    "        (sources['flux'] > lims[0], sources['flux'] < lims[1],\n",
    "         sources['xcentroid'] > 15, sources['ycentroid'] > 15,\n",
    "         sources['xcentroid'] < data.shape[1]-15, \n",
    "         sources['ycentroid'] < data.shape[0]-15\n",
    "        )\n",
    "    )\n",
    "\n",
    "    positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "    tree = KDTree(positions)\n",
    "    # nearest neighbours\n",
    "    dist, ind = tree.query(positions, 2)\n",
    "\n",
    "    # most isolated star of proper brightness\n",
    "    idx = dist[:, 1][mask].argmax()\n",
    "    location = positions[mask][idx]\n",
    "    cutout = Cutout2D(data, location.T, 15)\n",
    "\n",
    "    fig, axis = plt.subplots(nrows=1, ncols=2, figsize=(13, 6))\n",
    "    norm = ImageNormalize(cutout.data, interval=AsymmetricPercentileInterval(1, 99))\n",
    "    axis[0].imshow(cutout.data, cmap='Greys', origin='lower', norm=norm, interpolation='nearest')\n",
    "    axis[0].set_xlabel('X')\n",
    "    axis[0].set_ylabel('Y')\n",
    "\n",
    "    xc, yc = centroid_com(cutout.data)\n",
    "    x = np.arange(15) - xc\n",
    "    y = np.arange(15) - yc\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    R = np.sqrt(X**2 + Y**2)\n",
    "    axis[1].plot(R.ravel(), cutout.data.ravel(), '.')\n",
    "    axis[1].set_xlabel('Distance from centre of star')\n",
    "    axis[1].set_ylabel('Counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "\n",
    "The basic steps that we will work through in this workbook are:\n",
    "1. [Read in an image](#ReadImage)\n",
    "2. [Indentify stars in the image](#SourceList)\n",
    "3. [Measure the brightness of the stars in that image (aperture photometry)](#ApPhot)\n",
    "4. [Repeat the above steps for other filters](#BFilt)\n",
    "5. Determine photometric zeropoints using standard stars\n",
    "6. Apply the photometric zeropoints to your measured magnitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ReadImage'></a>\n",
    "\n",
    "# Read in your image\n",
    "\n",
    "Using the code cell below, read in one of your pre-calibrated Nickel images with plenty of stars. A good choice would be a long exposure V-band image. We're going to read the image into an array called `data` and read the header from the FITS file into a variable called `header`. \n",
    "\n",
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<font color='green'>\n",
    "<h2><span class=\"fa fa-pencil\"></span> Choose the image to use </h2>\n",
    "</font>   \n",
    "    \n",
    "**Set the input file (ifile) that you want to perform photometry on.**\n",
    "    \n",
    "</div>\n",
    "</section>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits,ascii\n",
    "import numpy as np\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.visualization import AsymmetricPercentileInterval\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import reduce\n",
    "from scipy.spatial import KDTree\n",
    "from astropy.nddata import Cutout2D\n",
    "from photutils.centroids import centroid_com\n",
    "\n",
    "# We need to set the gain of our CCD to allow us to measure errors correctly later\n",
    "# For the Nickel, gain is 2 e/ADU\n",
    "egain = 2.0\n",
    "ifile = '/home/jrees/DataReduction/20230720/Standards/d1084_os_bs_ff_bp_crj.fits'\n",
    "data, header = fits.getdata(ifile,header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='SourceList'></a>\n",
    "# Creating a Source List\n",
    "\n",
    "The first step is to detect our sources. We will do this using an algorithm called DAOFIND ([Stetson 1987, PASP, 99, 191](https://ui.adsabs.harvard.edu/abs/1987PASP...99..191S/abstract)). DAOFIND looks for bright regions in the image that have a peak brightness greater than some threshold and that have a size and shape similar to a Gaussian of specified FWHM.\n",
    "\n",
    "Stars in our image will stand out above the background, and DAOFIND will find them, but we need to know what threshold to use. One way of doing this is to measure the statistics of the **background** in our image. If we measure the average value of the background, and the amount the background varies, we can look for regions that are significantly brighter than background pixels. \n",
    "\n",
    "Below we will do that using a \"sigma-clipped\" mean - this estimates the average background and the standard deviation. We then throw away all the pixels more than 3 standard deviations (sigma) away from the mean, and repeat the process. We carry on until no pixels are more than 3 standard deviations away from the average value, then calculate the mean, median and standard deviation of the remaining pixels.\n",
    "\n",
    "You may want to tweak this value of sigma until you're happy with the sky level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sigma_clipping function from astropy\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "\n",
    "mean_background, median_background, background_standard_deviation = sigma_clipped_stats(data, sigma=3.0)\n",
    "\n",
    "print(\"The background has an average value of {:.1f} and a standard deviation of {:.1f} counts\".format(\n",
    "    mean_background, background_standard_deviation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Stars\n",
    "\n",
    "Now we know how bright our background is, and how much it varies, let's look for stars that are brighter than the background plus 5 standard deviations. That should be enough that we don't identify bright background pixels as stars by accident. The DAOFIND algorithm needs a guess for how big the stars are - as a Gaussian FWHM - we'll guess at 6 pixels for now, but you can tweak this further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from photutils.detection import DAOStarFinder\n",
    "\n",
    "# Set the fwhm initial guess\n",
    "fwhm = 6.0\n",
    "# make a star finder object to look for stars with FWHM~6 pixels that are more than 5-sigma above background\n",
    "daofind = DAOStarFinder(fwhm=fwhm, threshold=5*background_standard_deviation)\n",
    "\n",
    "# Mask the data to remove the edges/corners\n",
    "mask=np.ma.make_mask(data,copy=True,shrink=True,dtype=bool)\n",
    "mask[:,:]=False\n",
    "mask[950:,0:50]=True\n",
    "mask[0:50,0:50]=True\n",
    "mask[:,1010:]=True\n",
    "\n",
    "# use it to find stars. We'll subtract the background off first, so background pixels have an average value of 0\n",
    "sources = daofind(data - median_background,mask=mask)\n",
    "\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``sources`` variable contains a table of all the detected stars. There are various columns, but the ones we are interested in is the X and Y positions of the stars, which you can find with ```sources['xcentroid']``` and ```sources['ycentroid']```.\n",
    "\n",
    "But how do we know we've found most of the stars? Or if we are mistakenly identifying bright background pixels as stars? We can inspect our sources by-eye. To make this easier, we're going to use one of the handy functions written by Stuart Littlefair \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big should we make the red apertures (in pixels)?\n",
    "radius=fwhm\n",
    "# Set up the positions of stars (from DAOFIND) and the size of our apertures\n",
    "positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "apertures = CircularAperture(positions, r=radius)\n",
    "# Normalise the image\n",
    "norm = ImageNormalize(data, interval=AsymmetricPercentileInterval(5, 95))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "apertures.plot(color='red', lw=1.5, alpha=0.5)\n",
    "plt.imshow(data, cmap='Greys', origin='lower', norm=norm, interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweak the detection settings </h2>\n",
    "   \n",
    "The DAOFIND algorithm requires a threshold for star detection, and a typical FWHM of the stars in the images. Try different settings for these values, and see how they affect the detection of stars in your data. Make a decision about what values to use for this image.\n",
    "    \n",
    "\n",
    "\n",
    "# FWHM of stars in the image\n",
    "\n",
    "We will also need an estimate for the FWHM of stars in the image. We can estimate this by-eye by plotting a bright, isolated, star and plotting the brightness against distance from the star's centre. \n",
    "\n",
    "Again, a handy tool exists to do this already. \n",
    "\n",
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<font color='green'>\n",
    "<h2><span class=\"fa fa-pencil\"></span> Measure the FWHM of an isolated star </h2>\n",
    "</font>    \n",
    "    \n",
    "**Using the plot below, figure out your FWHM in pixels. You can then go back and update the value of fwhm. \n",
    "Using the Nickel plate scale you can convert it to arcseconds (you do remember the value right?)**\n",
    "    \n",
    "</div>\n",
    "</section>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_FWHM(data, sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aperture Photometry\n",
    "\n",
    "So, we have a list of detected sources and positions in the image, and an idea of the FWHM of stars in the image. Now we can perform aperture photometry on all of these sources. \n",
    "In brief the function performs the following steps:\n",
    "\n",
    "1. Add up the counts from each source within a target aperture\n",
    "2. Measure the sky brightness around each source using the sky annulus\n",
    "3. Subtract the sky contribution from the counts in step 1.\n",
    "4. Calculate instrumental magnitude from the counts and exposure time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ApPhot'></a>\n",
    "# Perform Aperture Photometry\n",
    "\n",
    "You'll need to pick values for the aperture radii. \n",
    "\n",
    "Target apertures want to be big enough to accept a decent fraction of the flux, but not so large that the measurements are very noisy, or contaminated by nearby stars. As a rule of thumb this aperture might have a radius of 1.5-2x the FWHM.\n",
    "\n",
    "Sky Annuli want to be wide enough to accurately measure the sky, but not so large that the annuli overlap nearby stars.\n",
    "\n",
    "To get started, try values around 15, 25, 35 pixels for these apertures. We can tweak them later on.\n",
    "\n",
    "If you want to view extra information about what 'aperture_photometry' is doing, you can do:\n",
    "\n",
    "help(aperture_photometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vmag_inst = aperture_photometry(data, header, sources, 15, 25, 35)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photometric Calibration\n",
    "\n",
    "Now we have a table of instrumental magnitudes (and much besides) in it. The next step is photometric calibration. As a reminder, this involves finding the average value of the *difference* between the calibrated and instrumental magnitudes for all our stars.\n",
    "\n",
    "There are a couple of options for determining our photometric calibration. Traditionally, we would observe 'standard stars', stars with well determined magnitudes. By observing these standard stars over a range of airmass we can determine the effect of atmospheric extinction, and determine photometric zeropoints as a function of airmass. \n",
    "\n",
    "This is a pretty involved process, and probably outside the scope of our data reduction activity this afternoon (though I have created the bare bones of an example in the nickel-standards notebook. \n",
    "\n",
    "With the advent of modern all-sky surveys we can also 'cheat' slightly, and use existing photometry from these all-sky surveys to provide our photometric calibrations. \n",
    "\n",
    "We will use the [APASS](https://www.aavso.org/apass) catalog; a catalog which combines several other sky surveys to provide data in many filters across much of the sky. Crucially, in this case it includes B, V, r, and i magnitudes, the filters used for our photometry (the r/i filters are not an exact match for our R and I filters, but close enough for this demonstration).\n",
    "\n",
    "To perform the cross-matching we will use the [astroquery](https://astroquery.readthedocs.io/en/latest/) Python library. \n",
    "\n",
    "To perform the cross-match, we'll need to determine an astrometric solution for our data. The astrometric solution will allow us to convert x-y pixel co-ordinates to RA-Dec co-ordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "from astroquery.xmatch import XMatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our photometry is stored as an astropy table, which is a handy object for reading and writing tabular data. These astropy tables play nicely with Jupyter notebooks, so you can simply type the name of the table in a code cell to see the table displayed in the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vmag_inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astrometric Solution\n",
    "\n",
    "To determine our astrometric solution we will make use of the Astrometry.net API. \n",
    "\n",
    "We already set up the API key earlier in this notebook, so now we can use solve_from_source_list to determine an astrometric solution from our source list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "\n",
    "# Sort sources in ascending order\n",
    "sources.sort('flux')\n",
    "# Reverse to get descending order\n",
    "sources.reverse()\n",
    "\n",
    "image_width = 1024\n",
    "image_height = 1024\n",
    "wcs_header = ast.solve_from_source_list(sources['xcentroid'], sources['ycentroid'],\n",
    "                                        image_width, image_height,\n",
    "                                        solve_timeout=120)\n",
    "print(\"Finished astrometric solve\")\n",
    "print(\"-----------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to apply the astrometric solution to our source table. We will replace the existing RA, DEC fields with new values based on the new solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = WCS(wcs_header)\n",
    "Vmag_inst['RA'], Vmag_inst['DEC'] = w.wcs_pix2world(Vmag_inst['xcenter'],Vmag_inst['ycenter'],1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our source table now has the measured centres of our stars in RA and Dec (**RA** and **DEC**) and the instrumental magnitude and uncertainty (**instrumental_mag** and **e_instrumental_mag**). Note that the magnitude uncertainty is calculated using the CCD signal-to-noise equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossmatching with APASS (or some other catalogue)\n",
    "\n",
    "\n",
    " We need to calibrate our photometry, which will involve comparing our instrumental magnitudes to calibrated magnitudes measured for the same stars. We need to match our detected stars with those catalogued in the sky survey [APASS](https://www.aavso.org/apass). We are looking for stars who's RA and Dec matches to within some radius. A service called **Vizier** hosts online versions of astronomical catalogs, and we can use the ```Xmatch.query``` function to match an astropy table with a table hosted by Vizier using the code below.\n",
    "\n",
    " Run the code cell below, and note carefully how we specify the columns that contain RA and Dec in our *local* table, and how we set the maximum distance for a valid match. **II/336/apass9** is the name of the APASS catalog on Vizier. If you need to find the names of other catalogs (perhaps APASS doesn't cover the patch of sky containing your open cluster), you can enter the catalog name in the search box [here](http://vizier.u-strasbg.fr)\n",
    " Something like UCAC4 or UCAC5 or GAIA might be good alternative choices\n",
    "\n",
    " **The code cell below may take a while to run. Be patient...**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmatch = XMatch.query(cat1=Vmag_inst, cat2='vizier:II/336/apass9', max_distance=2*u.arcsec, colRA1='RA', colDec1='DEC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the difference and find the zero-point\n",
    "\n",
    " Plot the difference between instrumental and calibrated magnitude found above, against the calibrated V-band magnitude on the X-axis. You should see something like the figure below:\n",
    "\n",
    "<img src=\"images/V_zeropoint.png\" style=\"margin: 0px\" width=750px/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_mag = xmatch['Vmag'] - xmatch['instrumental_mag']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(xmatch['Vmag'],delta_mag, 'bo')\n",
    "plt.xlabel('V Mag (APASS)')\n",
    "plt.ylabel('Delta V (APASS - Inst)')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magnitude difference between instrumental and calibrated magnitude (your Y-axis) *should* be a constant, which is the value of $kX + m_{\\rm zp}$. In the figure above, you can see there are plenty of outlying points, and the bright stars deviate from the constant. The outliers are either stars whose photometry is bad (poor sky estimation, or contaminated by very close stars), or spurious detections (i.e not stars). The deviation of the bright stars is caused because they are saturated, and so we cannot accurately measure their flux.\n",
    "\n",
    "Since $m = m_i - kX + m_{\\rm zp}$, we can find the value of $-kX + m_{\\rm zp}$. - which I'll call the *zeropoint* from now on - by calculating the **median** difference between the instrumental and calibrated magnitude. The median will be robust against the outliers - but we only want to do it for the non-saturated stars!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the zero-point\n",
    "\n",
    "> Calculate the median value of ```delta_mag```. **If you have evidence for saturated stars**, you can use a NumPy *mask* to only calculate the median of stars that are not saturated \n",
    "\n",
    "> The median value of ```delta_mag``` is our estimate of $-kX + m_{\\rm zp}$ - i.e the value we want to add to our instrumental magnitudes to get a calibrated magnitude. You can add this value to the **instrumental_mag** column of the VMag_inst table easily using ```VMag_inst['calibrated_mag'] = VMag_inst['instrumental_mag'] + zp```, where ```zp``` is the median value you found.\n",
    "\n",
    "<section class=\"challenge panel panel-success\"> \n",
    "<div class=\"panel-heading\">\n",
    "<font color='green'>\n",
    "<h2><span class=\"fa fa-pencil\"></span> Determine your zeropoint mask</h2>\n",
    "</font>    \n",
    "\n",
    "**Set the plotmask below to exclude any saturated stars.**\n",
    "    \n",
    "**Alternatively, if the crossmatch fails (usually due to a lack of stars) you can adopt 22.5 for V and 23.5 for B**\n",
    "\n",
    "</div>\n",
    "</section>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, just calculate the median:\n",
    "\n",
    "zp = np.median(delta_mag)\n",
    "print ('zeropoint = ', zp)\n",
    "\n",
    "# We could also use a mask to exclude saturated points. Replace 21.5 and 21.0 \n",
    "# with the upper/lower bounds of your 'good' data\n",
    "plotmask = (delta_mag > 22.4) #& (delta_mag > 21.0)\n",
    "delta_masked = delta_mag[plotmask]\n",
    "zp1 = np.median(delta_masked)\n",
    "print('Masked zeropoint = ',zp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeropoint_v = zp1\n",
    "# Now apply the zeropoint to the instrumental magnitudes\n",
    "Vmag_inst['calibrated_mag'] = Vmag_inst['instrumental_mag'] + zeropoint_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "# Other filters and making a CMD\n",
    "\n",
    "If we repeat the above steps for other images, we can measure our stellar magnitudes in all of our other filters\n",
    "\n",
    "<a id='BFilt'></a>\n",
    "# The B-band data\n",
    "\n",
    " Assuming that you started with V, repeat the steps for your B-band data. Make a plot of the difference between instrumental B-band magnitude and APASS B-band magnitude. Calculate the offset needed to correct your instrumental mags (zeropoint).\n",
    "\n",
    " Finally, add your zeropoint to the **instrumental_mag** column of the B-band table to make a new **calibrated_mag** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab the data\n",
    "ifile = '/home/jrees/DataReduction/20230720/Standards/d1080_os_bs_ff_bp_crj.fits'\n",
    "data, header = fits.getdata(ifile,header=True)\n",
    "\n",
    "# Measure the background\n",
    "mean_background, median_background, background_standard_deviation = sigma_clipped_stats(data, sigma=3.0)\n",
    "\n",
    "print(\"The background has an average value of {:.1f} and a standard deviation of {:.1f} counts\".format(\n",
    "    mean_background, background_standard_deviation))\n",
    "\n",
    "# Find the stars \n",
    "daofind = DAOStarFinder(fwhm=fwhm, threshold=5*background_standard_deviation)\n",
    "sources = daofind(data - median_background)\n",
    "print(sources)\n",
    "\n",
    "# Check everything looks good\n",
    "radius=fwhm\n",
    "positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "apertures = CircularAperture(positions, r=radius)\n",
    "norm = ImageNormalize(data, interval=AsymmetricPercentileInterval(5, 95))\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "apertures.plot(color='red', lw=1.5, alpha=0.5)\n",
    "plt.imshow(data, cmap='Greys', origin='lower', norm=norm, interpolation='nearest')\n",
    "\n",
    "# Take a look at the FWHM in this image\n",
    "measure_FWHM(data, sources)\n",
    "\n",
    "# Time for photometry\n",
    "Bmag_inst = aperture_photometry(data, header, sources, 15, 25, 35)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astrometry round 2\n",
    "\n",
    "Let's repeat the astrometric solve for this second image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort sources in ascending order\n",
    "sources.sort('flux')\n",
    "# Reverse to get descending order\n",
    "sources.reverse()\n",
    "\n",
    "image_width = 1024\n",
    "image_height = 1024\n",
    "wcs_header = ast.solve_from_source_list(sources['xcentroid'], sources['ycentroid'],\n",
    "                                        image_width, image_height,\n",
    "                                        solve_timeout=120)\n",
    "print(\"Finished astrometric solve\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "w = WCS(wcs_header)\n",
    "Bmag_inst['RA'], Bmag_inst['DEC'] = w.wcs_pix2world(Bmag_inst['xcenter'],Bmag_inst['ycenter'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossmatch with APASS\n",
    "\n",
    "Perform the APASS crossmatch for your second filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmatch2 = XMatch.query(cat1=Vmag_inst, cat2='vizier:II/336/apass9', max_distance=2*u.arcsec, colRA1='RA', colDec1='DEC')\n",
    "xmatch2\n",
    "\n",
    "delta_mag = xmatch2['Bmag'] - xmatch2['instrumental_mag']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(xmatch2['Bmag'],delta_mag, 'bo')\n",
    "plt.xlabel('B Mag (APASS)')\n",
    "plt.ylabel('Delta B (APASS - Inst)')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, just calculate the median:\n",
    "\n",
    "zp = np.median(delta_mag)\n",
    "print ('zeropoint = ', zp)\n",
    "\n",
    "# We could also use a mask to exclude saturated points. Replace 21.5 and 21.0 \n",
    "# with the upper/lower bounds of your 'good' data\n",
    "plotmask = (delta_mag > 23.4) #& (delta_mag > 21.0)\n",
    "delta_masked = delta_mag[plotmask]\n",
    "zp2 = np.median(delta_masked)\n",
    "print('Masked zeropoint = ',zp2)\n",
    "\n",
    "zeropoint_b = zp2\n",
    "# Now apply the zeropoint to the instrumental magnitudes\n",
    "Bmag_inst['calibrated_mag'] = Bmag_inst['instrumental_mag'] + zeropoint_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bmag_inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossmatching our calibrated magnitudes\n",
    "\n",
    "Now you should have a two astropy tables: One with calibrated V-band magnitudes and one with calibrated B-band magnitudes. We need to cross-match these tables with each other, to find which stars in the V-band table match with stars in the B-band table. We can't use ```astroquery```'s Xmatch for this, since they are both local tables. Instead, we will use the ```SkyCoord``` object from astropy, which is meant to work with coordinates on the sky. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "# Create a SkyCoord object for your first filter\n",
    "coo_v = SkyCoord(Vmag_inst['RA'], Vmag_inst['DEC'], unit=u.deg)\n",
    "\n",
    "# And for the second filter \n",
    "coo_b = SkyCoord(Bmag_inst['RA'], Bmag_inst['DEC'], unit=u.deg)\n",
    "\n",
    "# match every entry in coo_v with the nearest entry in coo_b to identify the same stars in each catalogue\n",
    "idx, distance_2d, distance_3d = coo_v.match_to_catalog_sky(coo_b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using idx as a slice for the Bmag_inst table will sort it so that Bmag_inst[0] is the closest match to Vmag_inst[0]\n",
    "Bmag_inst = Bmag_inst[idx]\n",
    "\n",
    "# And finally we have to ensure the closest match is actually useful. \n",
    "# Some of the 'closest matches' might actually be very far away. \n",
    "dist_mask = distance_2d < 3 * u.arcsec\n",
    "Bmag_inst = Bmag_inst[dist_mask]\n",
    "Vmag_inst = Vmag_inst[dist_mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting a CMD \n",
    "\n",
    " If we want to plot a CMD from our data, we can extract the calibrated magnitudes, calculate ```B-V``` and plot a colour-magnitude diagram of ```B-V``` against ```V```. Your plot should look something like the one below, which is for the cluster NGC 7789.\n",
    "\n",
    "<img src=\"./images/CMD.png\" style=\"margin: 0px\" width=750px/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = Bmag_inst['calibrated_mag']\n",
    "V = Vmag_inst['calibrated_mag']\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(B-V,V, 'bo')\n",
    "plt.xlabel('B-V')\n",
    "plt.ylabel('V Mag')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other filters\n",
    "\n",
    "If you have data in other filters (and time!) you can go ahead and repeat the above steps for the other filters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#R\n",
    "# Grab the data\n",
    "\n",
    "\n",
    "# Measure the background\n",
    "\n",
    "# Find the stars \n",
    "\n",
    "# Check everything looks good\n",
    "\n",
    "# Take a look at the FWHM in this image\n",
    "\n",
    "# Time for photometry\n",
    "\n",
    "# Astrometric solution\n",
    "\n",
    "# Match against APASS\n",
    "\n",
    "# Caluclate the zeropoint\n",
    "\n",
    "# Apply the zeropoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#I\n",
    "# Grab the data\n",
    "\n",
    "\n",
    "# Measure the background\n",
    "\n",
    "# Find the stars \n",
    "\n",
    "# Check everything looks good\n",
    "\n",
    "# Take a look at the FWHM in this image\n",
    "\n",
    "# Time for photometry\n",
    "\n",
    "# Astrometric solution\n",
    "\n",
    "# Match against APASS\n",
    "\n",
    "# Caluclate the zeropoint\n",
    "\n",
    "# Apply the zeropoint\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
